\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Bibliography Summaries}
\author{Kevin Le}
\date{October 2020}

\begin{document}

\maketitle

\section{Week 1 Bibliography Summaries}

	An engine was created for users and programmers to create their own 3D web based application with little to no struggle. It is composed of two main parts, the “Engine CORE” and the “Engine API” which is essential for the engine to function properly \cite{8955392}. The Engine CORE includes a method to handle and load glTF files, a physics and graphics controller which contains beneficial functions, and important 3D engines and graphic libraries to easily build the 3D environment. The Engine API on the other hand allows users to access all the functions in the Engine CORE. Together with the 3D open source software Blender, users can easily load in 3d objects with included physics and collisions on the web easily. Because of the growth of VR and AR this generation, the group behind the 3D application engine plans on adding these features in the future for a more engaging experience between the user and the web.
	
	The web is a place where users can engage with each other. One way is through a web based framework called VRIA where users can view data, plots, and graphs through VR with other people and actively engage with it. The experience is known as Immersive Analytics in which the goal is for users to feel more “immersed” through a web interactive and collaborative system. VRIA produced this experience by using WebVR for real time communications, DOM (Document Object Model) for web tools that help with functions of objects and JSON for data structure \cite{8954824}. Similar to the Engine CORE, the VRIA framework was made to be user friendly so that even those novice to programming can create an Immersive Analytics experience on the web. This is thanks to VRIA’s workflow which allows new programmers to just use the built in VRIA Builder that is already provided. Experienced programmers can avoid this route and use the apps code to develop their own experience too. From these articles and papers, I learned that computer graphics nowadays not only switched over to 3D, but it is doing its best to transition itself to a more user friendly and immersive experience through VR and AR. 

\section{Week 2 Bibliography Summaries}

Mobile phones today can do much more than what they could a few years ago. Most if not all phones now contain sensors and cameras that can help make everyone's lives easier. A good example of this is a sample app produced for field analysts called FieldView \cite{8805467}. Field analysts such as construction workers, firefighters and forestry's collect data to help people around a specific environment learn about its current condition. There are potential problems however such as datas requiring to be physically sent to a location for analyzing before getting feedback during an ongoing mission or more new data not being collected and updated after submitting data. These problems can be fixed with an app on the mobile phone which shows users a visualization system of the field they are operating on through AR. With a phone camera, sensor and cloud datastore with MySQL, field analysts can use Immersive Analysts (IA) to scan, update, and send data with little to no problem in real time. Users with the app can create a visual field with colored models to indicate what each color means, create their own interface when collecting data and update data collectively as a team. The fact that mobile phones can do AR with their cameras and sensors and be used as mini VR machines shows how much computer graphics have progressed.

Other researchers also took advantage of the mobile phones camera and sensor to create a monocular 3D reconstruction system. The app known as Mobile3DRecon was designed to fuse the virtual 3D world and real scene together to capture collision and occlusion in real time \cite{9201064}. This requires an online mesh generator with 6Dof tracking to constantly update the pixels of the virtual world when scanning with the real scenes. This idea seems like it requires strong hardware and would work better with a PC desktop. However the group behind Mobile3DRecon manage to make their app work by making the depth estimate and incremental mesh back end while making real time dense mesh and 6DoF front end. The team was able to produce a 3D reconstruction system with 1 CPU core on a mobile phone and was able to showcase how better it was compared to other applications such as MVDepthNet and DPSNet. The app was able to do the TSDF (Truncated Signed Distance Field) voxel method and incremental mesh update on a middle end phone. These papers showed how far mobile has progressed throughout the years and how it has grown more useful and stronger in the computer graphics field.  

\section{Week 3 Bibliography Summaries}

Shaders play an important role in computer graphics since it works alongside the GPU and helps generate 3D graphics accordingly. There are multiple types of shaders and all of them play a big part in the graphics pipeline. One of these shaders is called a tessellation shader and it handles terrains in open world games or CGI projects. Rendering wide terrain in real time while maintaining efficiency is key for a large open world game to run and play well. Tessellation shaders handle this type of situation by doing mesh refinements and culling in the GPU. However, some researchers found the usual method behind tessellation shaders to be a problem since the shaders max tessellation capacity is too low. Because of this, a new algorithm was proposed to create a new mesh shader pipeline to increase the max tessellations capacity \cite{9122336}. Increasing the capacity is known to cause low performances which the team behind this algorithm knew, so it was further modified to keep the culling and CPU efficient. The proposed function handled tessellation factors with task shaders, performed a culling pass method and relied heavily on mesh and task shaders. The results for the suggested algorithm proved to be promising and did indeed improve wide terrain tessellation. This paper demonstrated to the readers that there are ways to modify shader types to improve performances in computer graphics.

Shaders are programmed to make a 3D virtual environment look more detailed and at times realistic with its lighting, shadows, and other various graphical improvements. A small computer graphics team wanted to make virtual worlds more complex through the creation of  realistic weather behavior \cite{10.1145/3402942.3402995}. The paper focused on virtual winter environments where snows can be blown by winds, potentially accumulate, or be interacted by human movements. A proposed method was to utilize compute shaders so that a dynamic manipulation of meshes was created to make transformable surfaces behave accordingly. The process of this method was to have the render buffer implemented then the surface shader sent to the compute shader. This renders the mesh into separate frames in which each frame is then calculated in the GPU to have the vertices of the surfaces get updated and the mesh be manipulated in the compute shaders. When it came time to use the following method in a snowy environment with 100 reinforced learning AIs, the computer was able to pick up realistic weather behavior and run at a smooth 30 frames per second. From this article, I learned that shaders play a big role in making 3d virtual environments look realistic and at times run smooth.

\section{Week 4 Bibliography Summaries}

Out of all the computer hardware components, the one that is essential for computer graphics nowadays is the Graphics Processing Unit (GPU). GPU’s are important since they deal with frames and speeds in 3D graphic applications such as video games. The one key performance people look for in GPU’s is speed improvements since it enhances experiences in 3D applications. Computers users are always creating methods to further improve the GPU, one of them includes implementing a Turing method NVIDIA GPUs \cite{9151311}. Turing is used in this context to  boost performance enhancements and increase speedups in modern gaming applications. The design was used to counter load-to-use stall which increased speedups by around ten percent. By countering load-to-use stalls, the Turing was able to lower hit latency in global loads, enable configuration of data RAM through cache merge, and enable higher warp concurrency improving memory latency. I find speed performance in GPU’s to be very essential this generation since games today are all made up of large 3D environments. The faster the speed the better the experience and if Turing can indeed improve NVIDIA GPUs, I hope it gets implemented in the future for all NVIDIA GPUs.

GPUs provide high performance and handle data movement. Researchers notice however that the cost of swapping and moving data affects application performances negatively due to memory oversubscription. This is due to two main reasons, memory thrashing which occurs due to high latency of tasks and memory contention which causes leading tasks to suffer delay. To counter these problems in GPUs, researchers proposed two main ideas. One was to allow the GPU to access datas directly in the storage system to avoid swap in swap out and memory contention \cite{10.1145/3341105.3373866}. The memory contention aware priority assignment was created to reduce the length of latency tasks and prevent high swapping cost time which causes delay and performance issues. The other idea was to propose a virtual memory management to avoid the problem of memory thrashing. The key plan was to have the lowest priority task lead with the highest latency to avoid the highest priority task from suffering. When two of these ideas were used, latency for each task was significantly reduced and the highest priority task did not suffer from performances. The amount of improvements that can be made to the GPU is fascinating and makes me wonder what researchers will discover next in the future to further improve its performance. 

\section{Week 5 Bibliography Summaries}

Video games have continued to evolve graphically every few years since its creation. The oldest home game consoles used to contain games like Pong which consisted of mere pixels as graphics. Fast forward to today's graphics in some video games, everything looks realistic from the characters to the grasses on the floor. Gameplay used to be the main core part of video games, but due to the vast power of hardware in consoles these days, graphics has also become a must for most gamers. If programmed wrong, it can throw game users off and affect their gaming experiences.  It has come to the point where even the smallest details like character expressions matter and can affect gameplay experiences. A team researched a way to create real time muscle based facial animation using shell elements and force decomposition for instance [cite]. Shell elements are used to better model the muscle geometry while modal warping and force decomposition is used to achieve real time performance \cite{10.1145/3384382.3384531}. For shell elements, a geometrically driven energy function called “Thin Shell Dynamics” is created to allow for stretching and bending of the face. Since force plays an important role for muscles and skins to undergo stretch deformation, force decomposition was created to enable region of interest (ROI) for each muscle to move differently and accordingly. The results for both these techniques ended well with the 3D model faces reacting correctly. Although this paper focussed on using these techniques for medical teams, it can be noted that game companies also use similar programming mechanics to have video game characters react and look realistic as possible.	

Facial expressions and graphics in video games is one thing, but sound is another. According to Kenwright, sounds in video games create engagements with players, convey information, and impact mood and performances. In fact, a game with visuals but no sounds is not considered a game since it does not make players feel engaged and immersed which is the main goal of video games. Throughout the paper, Kenwright discussed all the different types of sounds that impact gameplay. From non linear sounds like how a weapon shoots to passive sounds like the background wind \cite{9098089}. There were also discussions on how sound recording and audio playback for game audio is more of a past tactic. Due to technological advances, most game companies now produce procedural sounds instead which relies on data extraction and training models (machine learning). Although Kenwright’s paper is considered a subject within the computer graphics field, it primarily focused on the importance of sounds in video games. Nothing about 3D models or graphics was really discussed. The only factor that was mentioned that slightly indicates computer graphics is the player’s sights in video games. A statement that Kenwright wrote about sights that I wholeheartedly agree is that sounds and sights is what defines a video game.

\section{Week 6 Bibliography Summaries}

Applying advanced lighting and shading to models can make them look realistic in any environment if done correctly. Online artists and game designers apply these techniques to make their work stand out since it creates immersion and projects realism. A team of 3D artists for instance proposed an approximate shading model method for image object modeling and insertion. The goal is to build an object relighting system that allows artists to select an object from an image and insert it into a 3D scene to make it look as if the image is part of the scene already \cite{7299168}. This technique takes an image fragment and simply puts it into another scene using a pure image based approach for shading consistency. The method does not involve using any 3D models surprisingly since the team behind it found them time consuming and hard to build. By doing object insertion, the group was able to cut time and resources and get the same if not better results than creating and inserting 3D models. The technique is decomposed into three main components. The first component being the smooth component involves using coarse shape. Coarse shape assumes the object to be inserted as an image and estimates its appearance under new illumination. An equation was formed under the team to find the coarse shape which handles the lighting. The other two components which handle shadings are the following, the gross shading and surface detail. With these three components, the group behind the approximate shading model method was able to produce promising results. Images and objects that are non 3D models and are inserted in 3D scenes look real and as if they were part of the environment the whole time. It is amazing to see how much advanced lightings and shadings can do to graphics nowadays. 
	
Advanced lightings and shadings have a powerful effect on 3D models and art since they help set the mood. A small team investigated commonly used lighting techniques on an animated virtual character to determine which one is more intense and the effects they have on people's mood \cite{10.1145/2931002.2931015}. The two lighting conditions used are low contrast lighting which uses a large area light to produce a subtle transition from light to dark on an illuminated area, and high contrast lighting which uses a small intense light source to produce hard shadows. These two lighting techniques were projected in different directions as well to demonstrate different intensities. Forty five degrees to the right, above and below the eye level, and no visible light direction at all. Two computer graphic shades, toon shading and smooth shading, were also used in order for the lighting to work properly for accurate results. All of the following that were mentioned are applied to a virtual character’s face which will be expressing five different emotions. Happiness, anger, sadness, fear, and disgust. Each person that played a part in the experiment had to deal with a total of 100 trials since they had to deal with five emotions, five lighting conditions, two shading styles, and two repetitions. The goal of the experiment was to see if people were able to identify what emotions the character was portraying, how expressive the emotions were portrayed, and how appealing the character was overall. The following results were found, smooth CG shading was rated more appealing than toon shading for all emotions and low contrast conditions were rated more appealing than high contrast conditions. The most interesting result found was that the intensity of emotion perception is consistent across lighting conditions for all emotions. For example, it was expected that the angry emotion with high contrast would be considered the most intense. This however was not the case and all emotions ended up having the same intensity! This paper showed more unique results lighting and shading has on computer graphics.

\section{Week 7 Bibliography Summaries}
	
Skeletons in computer graphics are composed of points which are centered inside shapes to provide a shape representation. 2D shapes contain a set of medial curves while 3D models contain a set of medial surfaces. For years, computer graphic researchers have found ways to extract curved skeletons. The common method used was called the grassfire analogy in which the shape boundary is set on “fire” to form a skeleton where the fire fronts meet and extinguish. The grassfire analogy is used to find the centeredness measurement which is needed to find the 3D curve skeleton. A team of researchers discovered that many people use the grassfire technique to form their own methods of extracting 3D curve skeletons. However most of these methods required tedious work and were costly. To avoid these conflicts and make the process easier, the group produced their own method which provided a simple and stable centeredness measurement that can run fast and produce high quality results \cite{9173765}. The method also employs minimum set covers to optimize ridges which helps generate clean and compact curve skeletons without the tedious adjustments. The process goes as follows, first the team generates the medial surface of the 3D shape. This is done by using a divergence based technique to detect ridges within the 3D model then using a connection strategy to connect these detected ridges with the gradient vectors. The team then performs centeredness measurement by creating their own algorithm which computes the burning time of a point on the medial surface. This algorithm creates centered points and contains two parts, a main loop that simulates fire propagation from a source point on the medial surface and a termination condition that checks if the manifold surface source point is broken or not. The centered points from the centeredness measurements then become optimized using the “minimum set covers” technique which creates a centeredness field. The optimized points are then connected through neighboring which produces the end result which is a 3D curve skeleton. The team used their new 3D curve skeleton method and compared them with three other known ones which were the ET, contradiction based, and advection based method. The result ended up being really positive with Li, Chu, and Wang’s 3D skeleton curve technique being the cleanest, accurate, and fastest one out of the three.
	
There are other factors that can affect curved surfaces in computer graphics as well like energy. An energy known as smoothness energy is used for optimization in geometry processing and can smooth data on surfaces, denoise data, and do various other things. The Laplacian energy for instance is a smoothness energy that uses minimizers to solve the biharmonic equation to create smooth results on computer graphic surfaces. However, the Laplacian energy uses the zero Neumann boundary condition which results in boundary distortions. A team wanted to apply smoothness energy on curved surfaces but wanted to avoid distortions as well. To achieve this, the group used a pre-made Hessian energy equation that was produced by a researcher named Stein and made further improvements and tweaks to it \cite{10.1145/3377406}. The team formed their own Hessian energy equation that took in curved surfaces since the previous one did not accommodate them and only took in surfaces in R2 space. The new Hessian energy basically corresponds to the Laplacian energy but with a “linear as possible” natural boundary to decrease distortion. Discretization which included the vector of Dirichlet’s energy and the Crouzeix Raviart formula was also used in the new equation for various smoothings and to solve interpolation problems. The team’s Hessian energy formula was able to apply smoothness energy towards curved surfaces while also avoiding distortions and other problems. I never knew how important curved surfaces were in computer graphics until I read these two papers which showed me how far researchers went to improve them. 
	
\section{Week 8 Bibliography Summaries}

\section{Week 9 Bibliography Summaries}

\section{Week 10 Bibliography Summaries}

\section{Week 11 Bibliography Summaries}

\section{Week 12 Bibliography Summaries}


\bibliographystyle{plain}
\bibliography{bibliography.bib}
\end{document}
