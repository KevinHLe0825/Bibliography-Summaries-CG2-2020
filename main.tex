\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Bibliography Summaries}
\author{Kevin Le}
\date{October 2020}

\begin{document}

\maketitle

\section{Week 1 Bibliography Summaries}

	An engine was created for users and programmers to create their own 3D web based application with little to no struggle. It is composed of two main parts, the “Engine CORE” and the “Engine API” which is essential for the engine to function properly \cite{8955392}. The Engine CORE includes a method to handle and load glTF files, a physics and graphics controller which contains beneficial functions, and important 3D engines and graphic libraries to easily build the 3D environment. The Engine API on the other hand allows users to access all the functions in the Engine CORE. Together with the 3D open source software Blender, users can easily load in 3d objects with included physics and collisions on the web easily. Because of the growth of VR and AR this generation, the group behind the 3D application engine plans on adding these features in the future for a more engaging experience between the user and the web.
	
	The web is a place where users can engage with each other. One way is through a web based framework called VRIA where users can view data, plots, and graphs through VR with other people and actively engage with it. The experience is known as Immersive Analytics in which the goal is for users to feel more “immersed” through a web interactive and collaborative system. VRIA produced this experience by using WebVR for real time communications, DOM (Document Object Model) for web tools that help with functions of objects and JSON for data structure \cite{8954824}. Similar to the Engine CORE, the VRIA framework was made to be user friendly so that even those novice to programming can create an Immersive Analytics experience on the web. This is thanks to VRIA’s workflow which allows new programmers to just use the built in VRIA Builder that is already provided. Experienced programmers can avoid this route and use the apps code to develop their own experience too. From these articles and papers, I learned that computer graphics nowadays not only switched over to 3D, but it is doing its best to transition itself to a more user friendly and immersive experience through VR and AR. 

\section{Week 2 Bibliography Summaries}

Mobile phones today can do much more than what they could a few years ago. Most if not all phones now contain sensors and cameras that can help make everyone's lives easier. A good example of this is a sample app produced for field analysts called FieldView \cite{8805467}. Field analysts such as construction workers, firefighters and forestry's collect data to help people around a specific environment learn about its current condition. There are potential problems however such as datas requiring to be physically sent to a location for analyzing before getting feedback during an ongoing mission or more new data not being collected and updated after submitting data. These problems can be fixed with an app on the mobile phone which shows users a visualization system of the field they are operating on through AR. With a phone camera, sensor and cloud datastore with MySQL, field analysts can use Immersive Analysts (IA) to scan, update, and send data with little to no problem in real time. Users with the app can create a visual field with colored models to indicate what each color means, create their own interface when collecting data and update data collectively as a team. The fact that mobile phones can do AR with their cameras and sensors and be used as mini VR machines shows how much computer graphics have progressed.

Other researchers also took advantage of the mobile phones camera and sensor to create a monocular 3D reconstruction system. The app known as Mobile3DRecon was designed to fuse the virtual 3D world and real scene together to capture collision and occlusion in real time \cite{9201064}. This requires an online mesh generator with 6Dof tracking to constantly update the pixels of the virtual world when scanning with the real scenes. This idea seems like it requires strong hardware and would work better with a PC desktop. However the group behind Mobile3DRecon manage to make their app work by making the depth estimate and incremental mesh back end while making real time dense mesh and 6DoF front end. The team was able to produce a 3D reconstruction system with 1 CPU core on a mobile phone and was able to showcase how better it was compared to other applications such as MVDepthNet and DPSNet. The app was able to do the TSDF (Truncated Signed Distance Field) voxel method and incremental mesh update on a middle end phone. These papers showed how far mobile has progressed throughout the years and how it has grown more useful and stronger in the computer graphics field.  

\section{Week 3 Bibliography Summaries}

Shaders play an important role in computer graphics since it works alongside the GPU and helps generate 3D graphics accordingly. There are multiple types of shaders and all of them play a big part in the graphics pipeline. One of these shaders is called a tessellation shader and it handles terrains in open world games or CGI projects. Rendering wide terrain in real time while maintaining efficiency is key for a large open world game to run and play well. Tessellation shaders handle this type of situation by doing mesh refinements and culling in the GPU. However, some researchers found the usual method behind tessellation shaders to be a problem since the shaders max tessellation capacity is too low. Because of this, a new algorithm was proposed to create a new mesh shader pipeline to increase the max tessellations capacity \cite{9122336}. Increasing the capacity is known to cause low performances which the team behind this algorithm knew, so it was further modified to keep the culling and CPU efficient. The proposed function handled tessellation factors with task shaders, performed a culling pass method and relied heavily on mesh and task shaders. The results for the suggested algorithm proved to be promising and did indeed improve wide terrain tessellation. This paper demonstrated to the readers that there are ways to modify shader types to improve performances in computer graphics.

Shaders are programmed to make a 3D virtual environment look more detailed and at times realistic with its lighting, shadows, and other various graphical improvements. A small computer graphics team wanted to make virtual worlds more complex through the creation of  realistic weather behavior \cite{10.1145/3402942.3402995}. The paper focused on virtual winter environments where snows can be blown by winds, potentially accumulate, or be interacted by human movements. A proposed method was to utilize compute shaders so that a dynamic manipulation of meshes was created to make transformable surfaces behave accordingly. The process of this method was to have the render buffer implemented then the surface shader sent to the compute shader. This renders the mesh into separate frames in which each frame is then calculated in the GPU to have the vertices of the surfaces get updated and the mesh be manipulated in the compute shaders. When it came time to use the following method in a snowy environment with 100 reinforced learning AIs, the computer was able to pick up realistic weather behavior and run at a smooth 30 frames per second. From this article, I learned that shaders play a big role in making 3d virtual environments look realistic and at times run smooth.

\section{Week 4 Bibliography Summaries}

Out of all the computer hardware components, the one that is essential for computer graphics nowadays is the Graphics Processing Unit (GPU). GPU’s are important since they deal with frames and speeds in 3D graphic applications such as video games. The one key performance people look for in GPU’s is speed improvements since it enhances experiences in 3D applications. Computers users are always creating methods to further improve the GPU, one of them includes implementing a Turing method NVIDIA GPUs \cite{9151311}. Turing is used in this context to  boost performance enhancements and increase speedups in modern gaming applications. The design was used to counter load-to-use stall which increased speedups by around ten percent. By countering load-to-use stalls, the Turing was able to lower hit latency in global loads, enable configuration of data RAM through cache merge, and enable higher warp concurrency improving memory latency. I find speed performance in GPU’s to be very essential this generation since games today are all made up of large 3D environments. The faster the speed the better the experience and if Turing can indeed improve NVIDIA GPUs, I hope it gets implemented in the future for all NVIDIA GPUs.

GPUs provide high performance and handle data movement. Researchers notice however that the cost of swapping and moving data affects application performances negatively due to memory oversubscription. This is due to two main reasons, memory thrashing which occurs due to high latency of tasks and memory contention which causes leading tasks to suffer delay. To counter these problems in GPUs, researchers proposed two main ideas. One was to allow the GPU to access datas directly in the storage system to avoid swap in swap out and memory contention \cite{10.1145/3341105.3373866}. The memory contention aware priority assignment was created to reduce the length of latency tasks and prevent high swapping cost time which causes delay and performance issues. The other idea was to propose a virtual memory management to avoid the problem of memory thrashing. The key plan was to have the lowest priority task lead with the highest latency to avoid the highest priority task from suffering. When two of these ideas were used, latency for each task was significantly reduced and the highest priority task did not suffer from performances. The amount of improvements that can be made to the GPU is fascinating and makes me wonder what researchers will discover next in the future to further improve its performance. 

\bibliographystyle{plain}
\bibliography{bibliography.bib}
\end{document}
